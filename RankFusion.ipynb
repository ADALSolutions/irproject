{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libraryIR import *    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We execute all basic algorithms of rank fusion and also Condorcet and Condorcet Weighted using 10 runs in input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condorcet WeightedML terminated without errors\n",
      "Condorcet WeightedLog terminated without errors\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We execute this cell to normalize all runs of input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path = os.getcwd()\n",
    "    \n",
    "dir_in = \"input\"   \n",
    "filename_list = listFiles(path, dir_in)\n",
    "\n",
    "dir_norm = \"norm\"\n",
    "manageDirectory(path, dir_norm)\n",
    "normalize_score_all(filename_list, path, dir_in, dir_norm)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We calculate the weight for each run in input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'condorcetWeightedLog.txt': 0.249314089371,\n",
       " 'condorcetWeightedML.txt': 0.249314089371}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd() \n",
    "dir_norm = \"comb\" \n",
    "dir_w = \"weights\"  \n",
    "findWeights(path, dir_norm, dir_w,exist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We look the MAP of all the runs in input and we order them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n_LemurTF_IDF_6.res', 0.260794490255), ('n_In_expB2c1.0_5.res', 0.259573429554), ('n_BB2c1.0_0.res', 0.256541726328), ('n_DFR_BM25c1.0_2.res', 0.243031010934), ('n_DLH_3.res', 0.239578158844), ('n_TF_IDF_9.res', 0.239240434152), ('n_BM25b0.75_1.res', 0.239048005853), ('n_PL2c1.0_8.res', 0.228062287682), ('n_DPH_4.res', 0.220347036976), ('n_LGDc1.0_7.res', 0.21876492326)]\n"
     ]
    }
   ],
   "source": [
    "weights_dict={'n_BB2c1.0_0.res': 0.218448258139,\n",
    " 'n_BM25b0.75_1.res': 0.208961047279,\n",
    " 'n_DFR_BM25c1.0_2.res': 0.211827556059,\n",
    " 'n_DLH_3.res': 0.204721421461,\n",
    " 'n_DPH_4.res': 0.197285743236,\n",
    " 'n_In_expB2c1.0_5.res': 0.223545296586,\n",
    " 'n_LGDc1.0_7.res': 0.19913679555,\n",
    " 'n_LemurTF_IDF_6.res': 0.220987874891,\n",
    " 'n_PL2c1.0_8.res': 0.193314809189,\n",
    " 'n_TF_IDF_9.res': 0.205028812476}\n",
    "import operator\n",
    "sorted_w = sorted(weights_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print sorted_w \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split pool in training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_pool=\"terrier-core-4.2\\\\share\\\\TIPSTER\\\\pool\\\\qrels.trec7.txt\"\n",
    "in_file = pd.read_csv(path_pool, delimiter = \" \", header = None)\n",
    "in_file.columns = [\"topicID\", \"q0\", \"docID\", \"state\"]\n",
    "df=in_file.loc[in_file[\"topicID\"]%2!=0]\n",
    "path_out=\"terrier-core-4.2\\\\share\\\\TIPSTER\\\\pool\\\\qrels.trec7_training.txt\"\n",
    "df.to_csv(path_out, index = False, header = False, sep = \" \")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_pool=\"terrier-core-4.2\\\\share\\\\TIPSTER\\\\pool\\\\qrels.trec7.txt\"\n",
    "in_file = pd.read_csv(path_pool, delimiter = \" \", header = None)\n",
    "in_file.columns = [\"topicID\", \"q0\", \"docID\", \"state\"]\n",
    "df=in_file.loc[in_file[\"topicID\"]%2==0]\n",
    "path_out=\"terrier-core-4.2\\\\share\\\\TIPSTER\\\\pool\\\\qrels.trec7_testing.txt\"\n",
    "df.to_csv(path_out, index = False, header = False, sep = \" \")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We compare MAP for each comb algorithm and we put in decreasing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Acquisisce MAP per ogni comb creata\n",
    "path = os.getcwd()    \n",
    "dir_in = \"input\"   \n",
    "dir_w = \"weights\"       \n",
    "dir_norm = \"norm\"\n",
    "dir_comb = \"comb\"\n",
    "\n",
    "filename_list = listFiles(path, dir_comb)\n",
    "results={}\n",
    "for filename in filename_list:\n",
    "    MAP=take_MAP(path,dir_comb,dir_w,filename,True)\n",
    "    results[filename]=MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comb_min.txt': 0.212459273216, 'comb_anz.txt': 0.251874925889, 'condorcet.txt': 0.249314089371, 'comb_median.txt': 0.248195018264, 'comb_max.txt': 0.247809472942, 'comb_mnz.txt': 0.254146091805, 'condorcetWeighted.txt': 0.251455071089, 'comb_sum.txt': 0.254682627063}\n",
      "\n",
      "\n",
      "[('comb_sum.txt', 0.254682627063), ('comb_mnz.txt', 0.254146091805), ('comb_anz.txt', 0.251874925889), ('condorcetWeighted.txt', 0.251455071089), ('condorcet.txt', 0.249314089371), ('comb_median.txt', 0.248195018264), ('comb_max.txt', 0.247809472942), ('comb_min.txt', 0.212459273216)]\n"
     ]
    }
   ],
   "source": [
    "print results\n",
    "print \"\\n\"\n",
    "import operator\n",
    "sorted_res = sorted(results.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print sorted_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
